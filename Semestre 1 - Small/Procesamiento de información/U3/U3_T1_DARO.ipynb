{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a428d97-9304-4f41-8657-82e1002fce10",
   "metadata": {
    "id": "338601e5-aee1-4f25-9296-3e123ba04d88"
   },
   "source": [
    "<center> <h2>Procesamiento de información </h2> </center>\n",
    "<center> <h2> Unidad 3 </h2> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c93571-5326-4e8c-a774-9b98b01dfaea",
   "metadata": {
    "id": "c9cdd7d1-6831-46da-af41-970d846f2107"
   },
   "source": [
    "<center>Marzo 2023</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfaf5ed-1cc9-482c-9722-954d6579665e",
   "metadata": {
    "id": "d76aacca-53ea-4a7f-966f-efc16314a141",
    "tags": []
   },
   "source": [
    "<center> Autor</center>\n",
    "<center> David Aarón Ramirez Olmeda </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d285a6b9-1866-4cb9-a0bf-4333957ea297",
   "metadata": {},
   "source": [
    "## Introducción:\n",
    "\n",
    "En la tarea a realizar se aplicarán técnicas de procesamiento de lenguaje natural para calcular modelos de probabilidad MLE y MLE con suavizado de Laplace para un modelo de bigramas utilizando el corpus \"europarl.es\". Además, se calcularán las probabilidades de ciertas oraciones utilizando ambos modelos y se realizarán predicciones de palabras dada una palabra inicial utilizando los modelos MLE y MLE con suavizado de Laplace."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04298be-c17e-48c9-bca2-f5a91d871c33",
   "metadata": {},
   "source": [
    "## Desarrollo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ae3624-7be9-44f4-a4e9-f7db01a1fcdc",
   "metadata": {},
   "source": [
    "### 1\n",
    "Calcular los modelos de probabilidad MLE y MLE con suavizado de Laplace para un modelo de bigramas. Con el corpus \"europarl.es\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0468d617-3142-45a7-af9a-b3b02f98b141",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from collections import Counter\n",
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b59f885-ed7e-4a03-8ae4-0b276ece17b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lectura y preprocesamiento del corpus\n",
    "with open(\"europarl.es\", \"r\", encoding=\"utf8\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "# Convertir a minúsculas y borrar puntuación\n",
    "text = text.lower()\n",
    "text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "\n",
    "# Agregar marcadores de inicio y fin de oración\n",
    "text = \"<s> \" + text.replace(\"\\n\", \" </s>\\n<s> \") + \" </s>\"\n",
    "\n",
    "# Separar el texto en oraciones\n",
    "sentences = text.split(\"\\n\")\n",
    "\n",
    "# Calcular la frecuencia de cada palabra y de cada bigrama\n",
    "unigram_counts = Counter()\n",
    "bigram_counts = Counter()\n",
    "for sentence in sentences:\n",
    "    tokens = sentence.split()\n",
    "    unigram_counts.update(tokens)\n",
    "    bigram_counts.update(zip(tokens, tokens[1:]))\n",
    "\n",
    "# Calcular la probabilidad MLE de cada bigrama\n",
    "mle_probabilities = {}\n",
    "for bigram, count in bigram_counts.items():\n",
    "    previous_word = bigram[0]\n",
    "    mle_probabilities[bigram] = count / unigram_counts[previous_word]\n",
    "\n",
    "# Calcular la probabilidad MLE con suavizado de Laplace de cada bigrama\n",
    "k = 1  # Constante de suavizado\n",
    "laplace_probabilities = {}\n",
    "for bigram, count in bigram_counts.items():\n",
    "    previous_word = bigram[0]\n",
    "    laplace_probabilities[bigram] = (count + k) / (unigram_counts[previous_word] + k*len(unigram_counts))\n",
    "\n",
    "# Guardar las probabilidades en archivos\n",
    "with open(\"mle_probabilities.pkl\", \"wb\") as f:\n",
    "    pickle.dump(mle_probabilities, f)\n",
    "\n",
    "with open(\"laplace_probabilities.pkl\", \"wb\") as f:\n",
    "    pickle.dump(laplace_probabilities, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ed3131-8a1d-4da7-921b-6275a6b1dd4d",
   "metadata": {},
   "source": [
    "Este código procesa el corpus de texto, calcula las frecuencias de palabras y bigramas, y calcula las probabilidades MLE y las probabilidades MLE con suavizado de Laplace de cada bigrama. Estas probabilidades se guardan en archivos para su uso posterior"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef0172a-0032-4f63-b29e-2fd2665d5986",
   "metadata": {},
   "source": [
    "### 2\n",
    "Calcular si la siguientes oraciones son posibles, es decir, calcular las probabilidades de las siguientes oraciones usando el modelo de MLE y MLE con suavizado de Laplace. Comparar las probabilidades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc6cf806-5952-4d1c-8e27-0852113f572b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oración: <s> el parlamento debe enviar un mensaje </s>\n",
      "Probabilidad MLE: 4.4374173769257393e-13\n",
      "Probabilidad MLE con suavizado de Laplace: 5.988734883346519e-21\n",
      "\n",
      "Oración: <s> el parlamento debe enviar un consejo </s>\n",
      "Probabilidad MLE: 3.357244293906632e-13\n",
      "Probabilidad MLE con suavizado de Laplace: 9.358867331905685e-20\n",
      "\n",
      "Oración: <s> el abismo entre pobres y ricos </s>\n",
      "Probabilidad MLE: 3.807854577012913e-17\n",
      "Probabilidad MLE con suavizado de Laplace: 1.673007647660524e-26\n",
      "\n",
      "Oración: <s> el abismo entre ricos y pobres </s>\n",
      "Probabilidad MLE: 8.648644418594847e-15\n",
      "Probabilidad MLE con suavizado de Laplace: 1.1611469745072447e-24\n",
      "\n",
      "Oración: <s> el abismo de la cantera entre pobres y ricos </s>\n",
      "Probabilidad MLE: 0.0\n",
      "Probabilidad MLE con suavizado de Laplace: 0.0\n",
      "\n",
      "Oración: <s> la comisión debe ser totalmente transparente </s>\n",
      "Probabilidad MLE: 3.597926526632743e-11\n",
      "Probabilidad MLE con suavizado de Laplace: 7.496239620326898e-19\n",
      "\n",
      "Oración: <s> la comisión debe ser transparente </s>\n",
      "Probabilidad MLE: 2.5521292162248256e-09\n",
      "Probabilidad MLE con suavizado de Laplace: 4.125572511955136e-15\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cargar los diccionarios de probabilidades\n",
    "with open(\"mle_probabilities.pkl\", \"rb\") as f:\n",
    "    mle_probabilities = pickle.load(f)\n",
    "\n",
    "with open(\"laplace_probabilities.pkl\", \"rb\") as f:\n",
    "    laplace_probabilities = pickle.load(f)\n",
    "\n",
    "# Función para calcular la probabilidad de una oración\n",
    "def calculate_sentence_probability(sentence, probabilities):\n",
    "    tokens = sentence.split()\n",
    "    probability = 1.0\n",
    "    for i in range(1, len(tokens)):\n",
    "        bigram = (tokens[i-1], tokens[i])\n",
    "        if bigram in probabilities:\n",
    "            probability *= probabilities[bigram]\n",
    "        else:\n",
    "            probability = 0.0\n",
    "            break\n",
    "    return probability\n",
    "\n",
    "# Calcular las probabilidades de las oraciones dadas\n",
    "sentences = [\"<s> el parlamento debe enviar un mensaje </s>\",\n",
    "             \"<s> el parlamento debe enviar un consejo </s>\",\n",
    "             \"<s> el abismo entre pobres y ricos </s>\",\n",
    "             \"<s> el abismo entre ricos y pobres </s>\",\n",
    "             \"<s> el abismo de la cantera entre pobres y ricos </s>\",\n",
    "             \"<s> la comisión debe ser totalmente transparente </s>\",\n",
    "             \"<s> la comisión debe ser transparente </s>\"]\n",
    "\n",
    "\n",
    "\n",
    "for sentence in sentences:\n",
    "    mle_probability = calculate_sentence_probability(sentence, mle_probabilities)\n",
    "    laplace_probability = calculate_sentence_probability(sentence, laplace_probabilities)\n",
    "    print(\"Oración:\", sentence)\n",
    "    print(\"Probabilidad MLE:\", mle_probability)\n",
    "    print(\"Probabilidad MLE con suavizado de Laplace:\", laplace_probability)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58f151e-32f6-45e6-a512-fd385cdd645c",
   "metadata": {},
   "source": [
    "Las probabilidades tan bajas que se muestran en la salida del código son comunes en el procesamiento del lenguaje natural y en particular en el modelado de lenguaje. Esto se debe a que la probabilidad de una oración se calcula multiplicando las probabilidades de sus bigramas, que son secuencias de dos palabras consecutivas. Como hay muchas combinaciones posibles de bigramas en una oración, la probabilidad total puede ser extremadamente baja. \n",
    "\n",
    "En el caso específico de este código, las probabilidades bajas también se deben a que se están usando modelos de lenguaje simples, basados únicamente en bigramas y sin tener en cuenta otras características lingüísticas más complejas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a51de5-e6c2-482c-82e4-c923b282a387",
   "metadata": {},
   "source": [
    "### 3 \n",
    "Predicción de palabras, dada una palabra inicial mostrar las siguientes cinco palabras más probables de acuerdo con los modelos MLE y MLE con suavizado de Laplace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c186fd83-3b72-4ad1-85e6-95a5abcfed53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Palabra</th>\n",
       "      <th>Prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLE</td>\n",
       "      <td>(los, estados)</td>\n",
       "      <td>6.97%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MLE</td>\n",
       "      <td>(los, países)</td>\n",
       "      <td>4.59%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MLE</td>\n",
       "      <td>(los, derechos)</td>\n",
       "      <td>3.64%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MLE</td>\n",
       "      <td>(los, que)</td>\n",
       "      <td>3.09%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MLE</td>\n",
       "      <td>(los, ciudadanos)</td>\n",
       "      <td>2.59%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Laplace</td>\n",
       "      <td>(los, estados)</td>\n",
       "      <td>3.61%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Laplace</td>\n",
       "      <td>(los, países)</td>\n",
       "      <td>2.38%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Laplace</td>\n",
       "      <td>(los, derechos)</td>\n",
       "      <td>1.89%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Laplace</td>\n",
       "      <td>(los, que)</td>\n",
       "      <td>1.60%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Laplace</td>\n",
       "      <td>(los, ciudadanos)</td>\n",
       "      <td>1.34%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MLE</td>\n",
       "      <td>(tribunales, nacionales)</td>\n",
       "      <td>12.12%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MLE</td>\n",
       "      <td>(tribunales, de)</td>\n",
       "      <td>11.36%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>MLE</td>\n",
       "      <td>(tribunales, y)</td>\n",
       "      <td>5.30%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>MLE</td>\n",
       "      <td>(tribunales, en)</td>\n",
       "      <td>4.55%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>MLE</td>\n",
       "      <td>(tribunales, del)</td>\n",
       "      <td>3.79%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Laplace</td>\n",
       "      <td>(tribunales, nacionales)</td>\n",
       "      <td>0.04%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Laplace</td>\n",
       "      <td>(tribunales, de)</td>\n",
       "      <td>0.03%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Laplace</td>\n",
       "      <td>(tribunales, y)</td>\n",
       "      <td>0.02%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Laplace</td>\n",
       "      <td>(tribunales, en)</td>\n",
       "      <td>0.01%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Laplace</td>\n",
       "      <td>(tribunales, del)</td>\n",
       "      <td>0.01%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>MLE</td>\n",
       "      <td>(nacionales, de)</td>\n",
       "      <td>13.61%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>MLE</td>\n",
       "      <td>(nacionales, y)</td>\n",
       "      <td>13.52%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>MLE</td>\n",
       "      <td>(nacionales, en)</td>\n",
       "      <td>5.01%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>MLE</td>\n",
       "      <td>(nacionales, que)</td>\n",
       "      <td>4.21%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>MLE</td>\n",
       "      <td>(nacionales, a)</td>\n",
       "      <td>1.88%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Laplace</td>\n",
       "      <td>(nacionales, de)</td>\n",
       "      <td>0.31%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Laplace</td>\n",
       "      <td>(nacionales, y)</td>\n",
       "      <td>0.31%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Laplace</td>\n",
       "      <td>(nacionales, en)</td>\n",
       "      <td>0.12%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Laplace</td>\n",
       "      <td>(nacionales, que)</td>\n",
       "      <td>0.10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Laplace</td>\n",
       "      <td>(nacionales, a)</td>\n",
       "      <td>0.04%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Modelo                   Palabra    Prob\n",
       "0       MLE            (los, estados)   6.97%\n",
       "1       MLE             (los, países)   4.59%\n",
       "2       MLE           (los, derechos)   3.64%\n",
       "3       MLE                (los, que)   3.09%\n",
       "4       MLE         (los, ciudadanos)   2.59%\n",
       "5   Laplace            (los, estados)   3.61%\n",
       "6   Laplace             (los, países)   2.38%\n",
       "7   Laplace           (los, derechos)   1.89%\n",
       "8   Laplace                (los, que)   1.60%\n",
       "9   Laplace         (los, ciudadanos)   1.34%\n",
       "10      MLE  (tribunales, nacionales)  12.12%\n",
       "11      MLE          (tribunales, de)  11.36%\n",
       "12      MLE           (tribunales, y)   5.30%\n",
       "13      MLE          (tribunales, en)   4.55%\n",
       "14      MLE         (tribunales, del)   3.79%\n",
       "15  Laplace  (tribunales, nacionales)   0.04%\n",
       "16  Laplace          (tribunales, de)   0.03%\n",
       "17  Laplace           (tribunales, y)   0.02%\n",
       "18  Laplace          (tribunales, en)   0.01%\n",
       "19  Laplace         (tribunales, del)   0.01%\n",
       "20      MLE          (nacionales, de)  13.61%\n",
       "21      MLE           (nacionales, y)  13.52%\n",
       "22      MLE          (nacionales, en)   5.01%\n",
       "23      MLE         (nacionales, que)   4.21%\n",
       "24      MLE           (nacionales, a)   1.88%\n",
       "25  Laplace          (nacionales, de)   0.31%\n",
       "26  Laplace           (nacionales, y)   0.31%\n",
       "27  Laplace          (nacionales, en)   0.12%\n",
       "28  Laplace         (nacionales, que)   0.10%\n",
       "29  Laplace           (nacionales, a)   0.04%"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = ['los', 'tribunales', 'nacionales']\n",
    "result = []\n",
    "for word in words:\n",
    "    res1 = {k: v for k, v in mle_probabilities.items() if k[0] == word and '</s>' not in k}\n",
    "    res1 = sorted(res1.items(), key=lambda x: (-x[1], x[0]))[0:5]\n",
    "    res2 = {k: v for k, v in laplace_probabilities.items() if k[0] == word and '</s>' not in k}\n",
    "    res2 = sorted(res2.items(), key=lambda x: (-x[1], x[0]))[0:5]\n",
    "    res1 = [('MLE', bigram[0], bigram[1]) for bigram in res1]\n",
    "    res2 = [('Laplace', bigram[0], bigram[1]) for bigram in res2]\n",
    "    result.extend(res1 + res2)\n",
    "    \n",
    "df = pd.DataFrame(result, columns=['Modelo', 'Palabra', 'Prob'])\n",
    "df['Prob'] = df['Prob'].apply(lambda x: f\"{x*100:.2f}%\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d75770-1e53-4a36-9f2a-c1dadd5e96d1",
   "metadata": {},
   "source": [
    "Este código es una forma de encontrar las cinco bigramas más probables que comienzan con cada palabra de la lista dada utilizando los dos modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5409eca6-0319-4cba-9608-a5098a752373",
   "metadata": {},
   "source": [
    "### 3.1\n",
    "\n",
    "Probar con el inicio de la palabra \"la\", probar con el inicio de la palabra \"parlamento\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bc27099-c942-4f05-b217-d3ba2443db37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Palabra</th>\n",
       "      <th>Prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLE</td>\n",
       "      <td>(la, comisión)</td>\n",
       "      <td>9.70%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MLE</td>\n",
       "      <td>(la, unión)</td>\n",
       "      <td>5.29%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MLE</td>\n",
       "      <td>(la, política)</td>\n",
       "      <td>1.63%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MLE</td>\n",
       "      <td>(la, sra)</td>\n",
       "      <td>1.40%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MLE</td>\n",
       "      <td>(la, ue)</td>\n",
       "      <td>1.35%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Laplace</td>\n",
       "      <td>(la, comisión)</td>\n",
       "      <td>6.89%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Laplace</td>\n",
       "      <td>(la, unión)</td>\n",
       "      <td>3.76%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Laplace</td>\n",
       "      <td>(la, política)</td>\n",
       "      <td>1.16%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Laplace</td>\n",
       "      <td>(la, sra)</td>\n",
       "      <td>1.00%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Laplace</td>\n",
       "      <td>(la, ue)</td>\n",
       "      <td>0.96%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MLE</td>\n",
       "      <td>(parlamento, europeo)</td>\n",
       "      <td>29.52%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MLE</td>\n",
       "      <td>(parlamento, y)</td>\n",
       "      <td>6.50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>MLE</td>\n",
       "      <td>(parlamento, en)</td>\n",
       "      <td>3.92%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>MLE</td>\n",
       "      <td>(parlamento, aprueba)</td>\n",
       "      <td>2.62%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>MLE</td>\n",
       "      <td>(parlamento, que)</td>\n",
       "      <td>2.62%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Laplace</td>\n",
       "      <td>(parlamento, europeo)</td>\n",
       "      <td>3.48%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Laplace</td>\n",
       "      <td>(parlamento, y)</td>\n",
       "      <td>0.77%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Laplace</td>\n",
       "      <td>(parlamento, en)</td>\n",
       "      <td>0.46%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Laplace</td>\n",
       "      <td>(parlamento, aprueba)</td>\n",
       "      <td>0.31%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Laplace</td>\n",
       "      <td>(parlamento, que)</td>\n",
       "      <td>0.31%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Modelo                Palabra    Prob\n",
       "0       MLE         (la, comisión)   9.70%\n",
       "1       MLE            (la, unión)   5.29%\n",
       "2       MLE         (la, política)   1.63%\n",
       "3       MLE              (la, sra)   1.40%\n",
       "4       MLE               (la, ue)   1.35%\n",
       "5   Laplace         (la, comisión)   6.89%\n",
       "6   Laplace            (la, unión)   3.76%\n",
       "7   Laplace         (la, política)   1.16%\n",
       "8   Laplace              (la, sra)   1.00%\n",
       "9   Laplace               (la, ue)   0.96%\n",
       "10      MLE  (parlamento, europeo)  29.52%\n",
       "11      MLE        (parlamento, y)   6.50%\n",
       "12      MLE       (parlamento, en)   3.92%\n",
       "13      MLE  (parlamento, aprueba)   2.62%\n",
       "14      MLE      (parlamento, que)   2.62%\n",
       "15  Laplace  (parlamento, europeo)   3.48%\n",
       "16  Laplace        (parlamento, y)   0.77%\n",
       "17  Laplace       (parlamento, en)   0.46%\n",
       "18  Laplace  (parlamento, aprueba)   0.31%\n",
       "19  Laplace      (parlamento, que)   0.31%"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = ['la', 'parlamento']\n",
    "result = []\n",
    "for word in words:\n",
    "    res1 = {k: v for k, v in mle_probabilities.items() if k[0] == word and '</s>' not in k}\n",
    "    res1 = sorted(res1.items(), key=lambda x: (-x[1], x[0]))[0:5]\n",
    "    res2 = {k: v for k, v in laplace_probabilities.items() if k[0] == word and '</s>' not in k}\n",
    "    res2 = sorted(res2.items(), key=lambda x: (-x[1], x[0]))[0:5]\n",
    "    res1 = [('MLE', bigram[0], bigram[1]) for bigram in res1]\n",
    "    res2 = [('Laplace', bigram[0], bigram[1]) for bigram in res2]\n",
    "    result.extend(res1 + res2)\n",
    "    \n",
    "df1 = pd.DataFrame(result, columns=['Modelo', 'Palabra', 'Prob'])\n",
    "df1['Prob'] = df1['Prob'].apply(lambda x: f\"{x*100:.2f}%\")\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee50b1e-b3e0-45d8-abe6-bdddcb43f291",
   "metadata": {},
   "source": [
    "Incluir 3 ejemplos para demostrar sus modelos de predicción \"interactiva\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c624331-66d6-4243-9397-81da282d5e94",
   "metadata": {},
   "source": [
    "1. Modelo de predicción MLE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fea6a03f-aa40-4943-bfeb-bcd7ae69398a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('español', 'que'), 0.12871287128712872),\n",
       " (('español', 'y'), 0.0891089108910891),\n",
       " (('español', 'en'), 0.0594059405940594),\n",
       " (('español', 'sr'), 0.039603960396039604),\n",
       " (('español', 'ha'), 0.0297029702970297)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res1 = {k: v for k, v in mle_probabilities.items() if k[0] == 'español' and '</s>' not in k}\n",
    "sorted(res1.items(), key=lambda x: (-x[1], x[0]))[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff005773-f151-4ae2-ac46-2ad433a504cc",
   "metadata": {},
   "source": [
    "2. Modelo de predicción con suavizado de Laplace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44594380-05a6-4e73-b76a-1dc0e9b02dde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('ojo', 'de'), 0.3333333333333333),\n",
       " (('ojo', 'la'), 0.16666666666666666),\n",
       " (('ojo', 'no'), 0.16666666666666666),\n",
       " (('ojo', 'para'), 0.16666666666666666),\n",
       " (('ojo', 'y'), 0.16666666666666666)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res1 = {k: v for k, v in mle_probabilities.items() if k[0] == 'ojo' and '</s>' not in k}\n",
    "sorted(res1.items(), key=lambda x: (-x[1], x[0]))[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fbe6db-f343-4594-a72c-92ad209b82b2",
   "metadata": {},
   "source": [
    "3. Modelo de predicción de la próxima palabra en una oración:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c890791-cf16-4ee7-a6e7-826c3fe80a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las tres siguientes palabras más probables son:\n",
      "1. de 0.1360787824529991\n",
      "2. y 0.135183527305282\n",
      "3. en 0.050134288272157566\n"
     ]
    }
   ],
   "source": [
    "text = 'los tribunales nacionales'\n",
    "words = text.split()\n",
    "previous_word = words[-1]\n",
    "\n",
    "next_words = []\n",
    "for bigram, probability in mle_probabilities.items():\n",
    "    if bigram[0] == previous_word and bigram[1] != \"</s>\":\n",
    "        next_words.append((bigram[1], probability))\n",
    "\n",
    "next_words = sorted(next_words, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Mostrar las tres siguientes palabras más probables\n",
    "print(\"Las tres siguientes palabras más probables son:\")\n",
    "for i in range(3):\n",
    "    if i < len(next_words):\n",
    "        print(f\"{i+1}. {next_words[i][0]} {next_words[i][1]}\")\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb92bc84-3b5b-41eb-98ff-7740d99c1f5f",
   "metadata": {},
   "source": [
    "## Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83beba68-a5ea-4998-bc50-724b5f296255",
   "metadata": {},
   "source": [
    "Se calculó la probabilidad de ciertas oraciones utilizando ambos modelos y se compararon las probabilidades. En general, esta tarea permite comprender cómo funcionan los modelos de lenguaje y cómo se pueden utilizar para realizar predicciones de palabras y calcular la probabilidad de ciertas oraciones."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
